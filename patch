books/bookvolbib add references

Goal: Proving Axiom Correct

\index{Meshveliani, Sergei D.}
\begin{chunk}{axiom.bib}
@misc{Mesh05,
  author = "Meshveliani, Sergei D.",
  title = {{Term rewriting, Equationional Reasoning, Automatic proofs}},
  link = "\url{ftp://ftp.botik.ru/pub/local/Mechveliani/dumatel/1.02/}",
  year = "2005",
  paper = "Mesh05.pdf"
}

\end{chunk}

\index{Davenport, James H.}
\begin{chunk}{axiom.bib}
@misc{Dave98,
  author = "Davenport, James H.",
  title = {{Is Computer Algebra the same as Computer Mathematics?}},
  year = "1998",
  comment = "Talk for British Colloquium for Theoretical Computer Science"
}

\end{chunk}

\index{Th\'ery, Laurent}
\begin{chunk}{axiom.bib}
@article{Ther98,
  author = "Thery, Laurent",
  title = {{A Certified Version of Buchberger's Algorithm}},
  journal = "LNCS",
  volume = "1421",
  pages = "349-364",
  year = "1998",
  abstract =
    "We present a proof of Buchberger's algorithm that has been developed
    in the Coq proof assistant. The formulation of the algorithm in Coq
    can be efficiently compiled and used to do computation",
  paper = "Ther98.pdf"
}

\end{chunk}

\index{Cooley, James W.}
\index{Tukey, John W.}
\begin{chunk}{axiom.bib}
@article{Cool65,
  author = "Cooley, James W. and Tukey, John W.",
  title = {{An Algorithm for the Machine Calculation of Complex Fourier 
            Series}},
  journal = "Mathematics of Computation",
  volume = "19",
  number = "04",
  year = "1965"
}

\end{chunk}

\index{Rump, Siegfried M.}
\begin{chunk}{axiom.bib}
@article{Rump88,
  author = "Rump, Siegfried M.",
  title = {{Algebraic Computation, Numerical Computation and Verified
            Inclusions}},
  journal = "LNCS",
  volume = "296",
  pages = "177-197",
  year = "1988",
  abstract = 
    "The three different types of computation -- the algebraic
    manipulation, the numerical computation and the computation of
    verified results -- are aiming on different problems and deliver
    qualitatively different results, each method having its specific
    advantages for specific classes of problems. The following remarks
    give some thoughts on possible combinations of all three methods to
    obtain algorithms benefitting from the specific strength of either
    method.",
  paper = "Rump88.pdf"
}

\end{chunk}

\index{Engelman, C.}
\begin{chunk}{axiom.bib}
@inproceedings{Enge65,
  author = "Engelman, C.",
  title = {{A Program for On-Line Assistance in Symbolic Computation}},
  booktitle = "Proc. Fall Joint Comput. Conf. 2",
  year = "1965",
  publisher = "Spartan Books"
}  

\end{chunk}

\index{Church, Alonzo}
\begin{chunk}{axiom.bib}
@article{Chur40,
  author = "Church, Alonzo",
  title = {{A Formulation of the Simple Theory of Types}},
  journal = "J. of Symbolic Logic",
  volume = "5",
  number = "2",
  year = "1940",
  pages = "56-68",
  abstract =
    "The purpose of the present paper is to give a formulation of the 
    simple theory of types which incorporates certain features of the
    calculus of $\lambda$-conversion. A complete incorporation of the
    calculus of $\lambda$-conversion into the theory of types is
    impossible if we require that $\lambda x$ and juxtaposition shall
    retain their respective meanings as an abstraction operator and as
    denoting the application of function to argument. But the present
    partial incorporation has certain advantages from the point of view of
    type theory and is offered as being of interest on this basis
    (whatever may be thought of the finally satisfactory character of the
    theory of types as a foundation for logic and mathematics).",
  paper = "Chur40.pdf"
}

\end{chunk}

\index{Redfern, D.}
\begin{chunk}{axiom.bib}
@book{Redf98,
  author = "Redfern, D.",
  title = {{The Maple Handbook: Maple V Release 5}},
  publisher = "Springer",
  year = "1998"
}

\end{chunk}

\index{Sorge, Volker}
\begin{chunk}{axiom.bib}
@misc{Sorg96,
  author = "Sorge, Volker",
  title = {{Integration eines Computeralgebrasystems in eine logische
            Beweisumgebung }},
  school = "Univ. des Saarlandes",
  year = "1996",
  comment = "Master's thesis"
}

\end{chunk}

\index{Farmer, William M.}
\index{Guttman, Joshua D.}
\index{Thayer, Javier}
\begin{chunk}{axiom.bib}
@article{Farm93a,
  author = "Farmer, William M. and Guttman, Joshua D. and Thayer, Javier",
  title = {{IMPS: An Interactive Mathematical Proof Systems}},
  journal = "J. of Automated Reasoning",
  volume = "11",
  pages = "213-248",
  year = "1993",
  abstract =
    "IMPS is an interactive mathematical proof system intended as a
    general-purpose too! formulating and applying mathematics in a
    familiar fashion.  The logic of IMPS is based on a version of simple
    type theory with partial functions and subtypes.  Mathematical
    specification and inference are performed relative to axiomatic
    theories, which can be related to one another via inclusion and theory
    interpretation.  IMPS provides relatively large primitive inference
    steps to facilitate human control of the deductive process and human
    comprehension of the resulting proofs.  An initial theory library con-
    taining over a thousand repeatable proofs covers significant portions
    of logic, algebra, and analysis and provides some support for modeling
    applications in computer science.",
  paper = "Farm93a.pdf"
}

\end{chunk}

\index{Bundy, Alan}
\index{Wallen, Lincoln}
\begin{chunk}{axiom.bib}
@inproceedings{Bund75,
  author = "Bundy, Alan and Wallen, Lincoln",
  title = {{The UT Theorem Prover}},
  booktitle = "Catalogue of Artificial Intelligence Tools",
  pages = "132-133",
  year = "1975",
  abstract =
    "The UT theorem prover is probably the best known natural deduction
    <153> theorem prover. It was written in LISP <34> by woody Bledsoe and
    his co-workers at the University of Texas, and is best described in
    (Bledsoe and Tyson 75]. The theorem prover embodies a Gentzen-like
    deduction system for first-order predicate calculus, and many special
    purpose techniques, including: subgoaling, rewrite rules, controlled
    lorward chaining, controlled definition instantiation, conditional
    procedures, and induction. The prover, though powerful in its own
    right, is essentially interactive and thus allows the user of the
    prover to control the search for the proof in radical ways. The user
    can for example : add hypotheses, instruct the prover to instantiate
    certain variables with values, or instruct the prover as to which
    deduction rule to use next."
}

\end{chunk}

\index{Bledsoe, W.W.}
\begin{chunk}{axiom.bib}
@techreport{Bled83,
  author = "Bledsoe, W.W.",
  title = {{The UT Natural Deduction Prover}},
  type = "technical report",
  institution = "Univ. of Texas at Austin",
  year = "1983",
  number = "ATP-17B"
}  

\end{chunk}

\index{Bledsoe, W.W.}
\begin{chunk}{axiom.bib}
@inproceedings{Bled84,
  author = "Bledsoe, W.W.",
  title = {{Some Automatic Proofs in Analysis}},
  booktitle = "Automated Theorem Proving: After 25 Years",
  publisher = "American Mathematical Society",
  year = "1984"
}

\end{chunk}

\index{Bledsoe, W.W.}
\index{Bruell, P.}
\index{Shostak, R.}
\begin{chunk}{axiom.bib}
@techreport{Bled79,
  author = "Bledsoe, W.W. and Bruell, P. and Shostak, R.",
  title = {{A Prover for General Inequalities}},
  type = "technical report",
  institution = "Univ. of Texas at Austin",
  year = "1979",
  number = "ATP-40A"
}

\end{chunk}

\index{Fitting, M.}
\begin{chunk}{axiom.bib}
@book{Fitt90,
  author = "Fitting, M.",
  title = {{First-order Logic and Automated Theorem Proving}},
  publisher = "Springer-Verlag",
  year = "1990",
  isbn = "978-1461275152"
}

\end{chunk}

\index{Gallier, Jean H.}
\begin{chunk}{axiom.bib}
@book{Gall86,
  author = "Gallier, Jean H.",
  title = {{Logic for Computer Science: Foundations of Automatic
            Theorem Proving}},
  publisher = "Harper and Row",
  year = "1986",
  isbn = "978-0486780825"
}

\end{chunk}

\index{Guessarian, Irene}
\index{Meseguer, Jose}
\begin{chunk}{axiom.bib}
@article{Gues87,
  author = "Guessarian, Irene and Meseguer, Jose",
  title = {{On the Axiomatization of ``IF-THEN-ELSE''}},
  journal = "SIAM J. Comput.",
  volume = "16",
  numbrrer = "2",
  year = "1987",
  pages = "332-357",
  abstract =
    "The equationally complete proof system for ``if-then-else'' of Bloom
    and Tindell is extended to a complete proof system for many-osrted
    algebras with extra operations, predicates and equations among
    those. We give similar completeness results for continuous algebras
    and program schemes (infinite trees) by the methods of algebraic
    semantics. These extensions provide a purely equational proof system
    to prove properties of functional programs over user-definable data
    types.",
  paper = "Gues87.pdf"
}

\end{chunk}

\index{Cunningham, R.J.}
\index{Dick, A.J.J}
\begin{chunk}{axiom.bib}
@article{Cunn85,
  author = "Cunningham, R.J. and Dick, A.J.J",
  title = {{Rewrite Systems on a Lattice of Types}},
  journal = "Acta Informatica",
  volume = "22",
  pages = "149-169",
  year = "1985",
  abstract =
    "Re-writing systems for partial algebras are developed by modifying
    the Knuth-Bendix completion algorithm to permit the use of
    lattice-structured domains. Some problems with the original algorithm,
    such as the treatment of division rings, are overcome conveniently by
    this means. The use of a type lattice also gives a natural framework
    for specifying data types in Computer Science without over-specifying
    error situations. The soundness and meaning of the major concepts
    involed in re-writing systems are reviewed when applied to such
    structures.", 
  paper = "Cunn85.pdf"
}

\end{chunk}

\index{Paulson, Lawrence C.}
\begin{chunk}{axiom.bib}
@article{Paul90,
  author = "Paulson, Lawrence C.",
  title = {{A Formulation of the Simple Theory of Types (for
            Isabelle}}},
  journal = "LNCS",
  volume = "417",
  pages = "246-274",
  year = "1990",
  abstract =
    "Simple type theory is formulated for use with the generic theorem
    prover Isabelle. This requires explicit type inference rules. There
    are function, product, and subset types, which may be
    empty. Descriptions (the eta-operator) introduce the Axiom of
    Choice. Higher-order logic is obtained through reflection between
    formulae and terms of type bool. Recursive types and functions can be
    formally constructed. Isabelle proof procedures are described. The
    logic appears suitable for general mathematics as well as
    computational problems.",
  paper = "Paul90.pdf"
}

\end{chunk}

\index{Kelsey, Tom}
\begin{chunk}{axiom.bib}
@phdthesis{Kels99,
  author = "Kelsey, Tom",
  title = {{Formal Methods and Computer Algebra: A Larch Specification of 
          AXIOM Categories and Functors}},
  school = "University of St Andrews",
  year = "1999",
  keywords = "axiomref"
}

\end{chunk}

\index{Lee, Wonyeol}
\index{Sharma, Rahul}
\index{Aiken, Alex}
\begin{chunk}{axiom.bib}
@article{Wony18,
  author = "Lee, Wonyeol and Sharma, Rahul and Aiken, Alex",
  title = {{On Automatically Proving the Correctness of math.h 
            Implementation}},
  journal = "Proc. ACM Programming Languages",
  volume = "2",
  number = "42",
  year = "2018",
  pages = "1-32",
  abstract = 
    "Industry standard implementations of math.h claim (often without
    formal proof) tight bounds on floating- point errors. We demonstrate a
    novel static analysis that proves these bounds and verifies the
    correctness of these implementations. Our key insight is a reduction
    of this verification task to a set of mathematical optimization
    problems that can be solved by off-the-shelf computer algebra
    systems. We use this analysis to prove the correctness of
    implementations in Intelâ€™s math library automatically. Prior to this
    work, these implementations could only be verified with significant
    manual effort.",
  paper = "Wony18.pdf"
}

\end{chunk}

\index{Daly, Timothy}
\begin{chunk}{axiom.bib}
@misc{Daly10,
  author = "Daly, Timothy",
  title = {{Intel Instruction Semantics Generator}},
  link = "\url{http://daly.axiom-developer.org/TimothyDaly_files/publications/sei/intel/intel.pdf}",
  abstract = 
    "Given an Intel x86 binary, extract the semantics of the instruction
    stream as Conditional Concurrent Assignments (CCAs). These CCAs 
    represent the semantics of each individual instruction. They can be
    composed to represent higher level semantics.",
  paper = "Daly10.pdf"
}

\end{chunk}

\index{Naylor, William A.}
\begin{chunk}{axiom.bib}
@phdthesis{Nayl00,
  author = "Naylor, Bill",
  title = {{Polynomial GCD Using Straight Line Program Representation}},
  school = "University of Bath",
  year = "2000",
  link = "\url{http://www.sci.csd.uwo.ca/~bill/thesis.ps}",
  abstract = "
    This thesis is concerned with calculating polynomial greatest common
    divisors using straight line program representation.

    In the Introduction chapter, we introduce the problem and describe
    some of the traditional representations for polynomials, we then talk
    about some of the general subjects central to the thesis, terminating
    with a synopsis of the category theory which is central to the Axiom
    computer algebra system used during this research.

    The second chapter is devoted to describing category theory. We follow
    with a chapter detailing the important sections of computer code
    written in order to investigate the straight line program subject.
    The following chapter on evalution strategies and algorithms which are
    dependant on these follows, the major algorith which is dependant on
    evaluation and which is central to our theis being that of equality
    checking. This is indeed central to many mathematical problems.
    Interpolation, that is the determination of coefficients of a
    polynomial is the subject of the next chapter. This is very important
    for many straight line program algorithms, as their non-canonical
    structure implies that it is relatively difficult to determine
    coefficients, these being the basic objects that many algorithms work
    on. We talk about three separate interpolation techniques and compare
    their advantages and disadvantages. The final two chapters describe
    some of the results we have obtained from this research and finally
    conclusions we have drawn as to the viability of the straight line
    program approach and possible extensions.

    Finally we terminate with a number of appendices discussing side
    subjects encountered during the thesis.",
  paper = "Nayl00.pdf"
}

\end{chunk}

\index{Shoup, Victor}
\begin{chunk}{axiom.bib}
@inproceedings{Shou93,
  author = "Shoup, Victor",
  title = {{Factoring Polynomials over Finite Fields: 
            Asymptotic Complexity vs Reality*}},
  booktitle = "Proc. IMACS Symposium, Lille, France",
  year = "1993",
  link = "\url{http://www.shoup.net/papers/lille.pdf}",
  abstract = 
    "This paper compares the algorithms by Berlekamp, Cantor and
    Zassenhaus, and Gathen and Shoup to conclude that (a) if large
    polynomials are factored the FFT should be used for polynomial
    multiplication and division, (b) Gathen and Shoup should be used if
    the number of irreducible factors of $f$ is small.  (c) if nothing is
    know about the degrees of the factors then Berlekamp's algorithm
    should be used.",
  paper = "Shou93.pdf"
}

\end{chunk}

\index{Wang, Paul S.}
\begin{chunk}{axiom.bib}
@article{Wang78,
  author = "Wang, Paul S.",
  title = {{An Improved Multivariate Polynomial Factoring Algorithm}},
  journal = "Mathematics of Computation",
  volume = "32",
  number = "144",
  year = "1978",
  pages = "1215-1231",
  link = "\url{http://www.ams.org/journals/mcom/1978-32-144/S0025-5718-1978-0568284-3/S0025-5718-1978-0568284-3.pdf}",
  abstract = "
    A new algorithm for factoring multivariate polynomials over the
    integers based on an algorithm by Wang and Rothschild is described.
    The new algorithm has improved strategies for dealing with the known
    problems of the original algorithm, namely, the leading coefficient
    problem, the bad-zero problem and the occurence of extraneous factors.
    It has an algorithm for correctly predetermining leading coefficients
    of the factors. A new and efficient p-adic algorith named EEZ is
    described. Basically it is a linearly convergent variable-by-variable
    parallel construction. The improved algorithm is generally faster and
    requires less store than the original algorithm. Machine examples with
    comparative timing are included.",
  paper = "Wang78.pdf"
}

\end{chunk}

\index{Baez, John C.}
\index{Stay, Mike}
\begin{chunk}{axiom.bib}
@misc{Baez09,
  author = "Baez, John C.; Stay, Mike",
  title = {{Physics, Topology, Logic and Computation: A Rosetta Stone}},
  link = "\url{http://arxiv.org/pdf/0903.0340v3.pdf}",
  abstract = "
    In physics, Feynman diagrams are used to reason about quantum
    processes.  In the 1980s, it became clear that underlying these
    diagrams is a powerful analogy between quantum physics and
    topology. Namely, a linear operator behaves very much like a
    ``cobordism'': a manifold representing spacetime, going between two
    manifolds representing space.  But this was just the beginning: simiar
    diagrams can be used to reason about logic, where they represent
    proofs, and computation, where they represent programs. With the rise
    of interest in quantum cryptography and quantum computation, it became
    clear that there is an extensive network of analogies between physics,
    topology, logic and computation. In this expository paper, we make
    some of these analogies precise using the concept of ``closed
    symmetric monodial category''. We assume no prior knowledge of
    category theory, proof theory or computer science.",
  paper = "Baez09.pdf"
}

\end{chunk}

\index{Dunstan, Martin}
\begin{chunk}{axiom.bib}
@misc{Duns00,
  author = "Dunstan, Martin N.",
  title = {{Adding Larch/Aldor Specifications to Aldor}},
  abstract = 
    "We describe a proposal to add Larch-style annotations to the Aldor
    programming language, based on our PhD research. The annotations
    are intended to be machine-checkable and may be used for a variety
    of purposes ranging from compiler optimizations to verification
    condition (VC) generation. In this report we highlight the options
    available and describe the changes which would need to be made to
    the compiler to make use of this technology.",
  paper = "Duns00.pdf",
  keywords = "axiomref"
}

\end{chunk}

\index{Thompson, Simon}
\begin{chunk}{axiom.bib}
@InProceedings{Thom01,
  author = "Thompson, Simon",
  title = {{Logic and dependent types in the Aldor Computer Algebra System}},
  booktitle = "Symbolic computation and automated reasoning",
  series = "CALCULEMUS 2000",
  year = "2001",
  location = "St. Andrews, Scotland",
  pages = "205-233",
  link = 
    "\url{http://axiom-wiki.newsynthesis.org/public/refs/aldor-calc2000.pdf}",
  abstract = 
    "We show how the Aldor type system can represent propositions of
    first-order logic, by means of the 'propositions as types'
    correspondence. The representation relies on type casts (using
    pretend) but can be viewed as a prototype implementation of a modified
    type system with {\sl type evaluation} reported elsewhere. The logic
    is used to provide an axiomatisation of a number of familiar Aldor
    categories as well as a type of vectors.",
  paper = "Thom01.pdf",
  keywords = "axiomref"
}

\end{chunk}

\index{Newcombe, Chris}
\index{Rath, Tim}
\index{Zhang, Fan}
\index{Munteanu, Bogdan}
\index{Brooker, Marc}
\index{Deardeuff, Michael}
\begin{chunk}{axiom.bib}
@misc{Newc13,
  author = "Newcombe, Chris and  Rath, Tim and  Zhang, Fan and
            Munteanu, Bogdan and  Brooker, Marc and Deardeuff, Michael",
  title = {{Use of Formal Methods at Amazon Web Services}},
  link = "\url{http://research.microsoft.com/en-us/um/people/lamport/tla/formal-methods-amazon.pdf}",
  abstract = 
    "In order to find subtle bugs in a system design, it is necessary to
    have a precise description of that design. There are at least two
    major benefits to writing a precise design; the author is forced to
    think more clearly, which helps eliminate ``plausible hand-waving'',
    and tools can be applied to check for errors in the design, even while
    it is being written. In contrast, conventional design documents
    consist of prose, static diagrams, and perhaps pseudo-code in an ad
    hoc untestable language. Such descriptions are far from precise; they
    are often ambiguous, or omit critical aspects such as partial failure
    or the granularity of concurrency (i.e. which constructs are assumed
    to be atomic). At the other end of the spectrum, the final executable
    code is unambiguous, but contains an overwhelming amount of detail. We
    needed to be able to capture the essence of a design in a few hundred
    lines of precise description. As our designs are unavoidably complex,
    we need a highly-expressive language, far above the level of code, but
    with precise semantics. That expressivity must cover real-world
    concurrency and fault-tolerance. And, as we wish to build services
    quickly, we wanted a language that is simple to learn and apply,
    avoiding esoteric concepts. We also very much wanted an existing
    ecosystem of tools.  We found what we were looking for in TLA+, a
    formal specification language."
}

\end{chunk}

\index{O'Connor, Liam}
\begin{chunk}{axiom.bib}
@misc{OCon15,
  author = {O'Connor, Liam},
  title = {{Write Your Compiler by Proving It Correct}},
  year = "2015",
  link = "\url{http://liamoc.net/posts/2015-08-23-verified-compiler.html}",
  abstract =
    "Recently my research has been centered around the development of a
    self-certifying compiler for a functional language with linear types
    called Cogent (see O'Connor et al. [2016]). The compiler works by
    emitting, along with generated low-level code, a proof in Isabelle/HOL
    (see Nipkow et al. [2002]) that the generated code is a refinement of
    the original program, expressed via a simple functional semantics in HOL.

    As dependent types unify for us the language of code and proof, my
    current endeavour has been to explore how such a compiler would look
    if it were implemented and verified in a dependently typed programming
    language instead. In this post, I implement and verify a toy compiler
    for a language of arithmetic expressions and variables to an idealised
    assembly language for a virtual stack machine, and explain some of the
    useful features that dependent types give us for writing verified
    compilers."
}

\end{chunk}

\index{Briggs, Keith}
\begin{chunk}{axiom.bib}
@misc{Brig04,
  author = "Briggs, Keith",
  title = {{Exact real arithmetic}},
  link = "\url{http://keithbriggs.info/documents/xr-kent-talk-pp.pdf}",
  year = "2004",
  paper = "Bri04.pdf"
}

\end{chunk}

\index{Fateman, Richard J.}
\index{Yan, Tak W.}
\begin{chunk}{axiom.bib}
@misc{Fate94a,
  author = "Fateman, Richard J.; Yan, Tak W.",
  title ={{Computation with the Extended Rational Numbers and an 
           Application to Interval Arithmetic}},
  link = "\url{http://www.cs.berkeley.edu/~fateman/papers/extrat.pdf}",
  abstract = "
    Programming languages such as Common Lisp, and virtually every
    computer algebra system (CAS), support exact arbitrary-precision
    integer arithmetic as well as exect rational number computation.
    Several CAS include interval arithmetic directly, but not in the
    extended form indicated here. We explain why changes to the usual
    rational number system to include infinity and ``not-a-number'' may be
    useful, especially to support robust interval computation. We describe
    techniques for implementing these changes.",
  paper = "Fate94a.pdf"
}

\end{chunk}

\index{Atkinson, Kendall}
\index{Han, Welmin}
\index{Stewear, David}
\begin{chunk}{axiom.bib}
@misc{Atki09,
  author = "Atkinson, Kendall and Han, Welmin and Stewear, David",
  title = {{Numerical Solution of Ordinary Differential Equations}},
  link =
     "\url{http://homepage.math.uiowa.edu/~atkinson/papers/NAODE_Book.pdf}",
  abstract = "
    This book is an expanded version of supplementary notes that we used
    for a course on ordinary differential equations for upper-division
    undergraduate students and beginning graduate students in mathematics,
    engineering, and sciences. The book introduces the numerical analysis
    of differential equations, describing the mathematical background for
    understanding numerical methods and giving information on what to
    expect when using them. As a reason for studying numerical methods as
    a part of a more general course on differential equations, many of the
    basic ideas of the numerical analysis of differential equations are
    tied closely to theoretical behavior associated with the problem being
    solved. For example, the criteria for the stability of a numerical
    method is closely connected to the stability of the differential
    equation problem being solved.",
  paper = "Atki09.pdf"
}

\end{chunk}
